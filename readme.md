# ğŸ¤– Natural Language AI Sales ChatBot

**AI-powered sales consultant with natural language generation, local database search, and Google fallback**

[![Python](https://img.shields.io/badge/Python-3.9+-blue.svg)](https://python.org)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)](https://pytorch.org)
[![CUDA](https://img.shields.io/badge/CUDA-11.8+-green.svg)](https://developer.nvidia.com/cuda-toolkit)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

## ğŸš€ **Key Features**

âœ… **Natural Language Generation** - Uses local LLM (Llama 2, Mistral) for human-like responses  
âœ… **Intelligent Search Priority** - Local database â†’ Google search â†’ AI-generated responses  
âœ… **Multi-GPU Optimization** - RTX 4090 + RTX 4070Ti Super support  
âœ… **Document Processing** - Excel, PDF, Word, Image (OCR) support  
âœ… **Conversation Context** - Remembers conversation history for natural dialogue  
âœ… **Real-time Analytics** - Performance monitoring and conversation analytics  

## ğŸ¯ **Demo**

```
User: "I need a gaming laptop under $2000"

AI Process:
1. ğŸ” Searches local product database using AI embeddings
2. âœ… Finds relevant products with 89% similarity match  
3. ğŸ¤– Generates natural response using Llama 2 LLM
4. ğŸ“Š Response time: 2.3 seconds

AI Response: "I'd recommend our Gaming Laptop Pro X1 at $1,899.99. 
It features an RTX 4070 graphics card and Intel i7-12700H processor 
with 32GB DDR5 RAM, making it excellent for gaming within your budget. 
The 15.6-inch 144Hz display ensures smooth gameplay, and it's currently 
in stock. Would you like to know more about its gaming performance?"
```

## ğŸ–¥ï¸ **Hardware Requirements**

### **Minimum Setup**
- **GPU**: RTX 4070Ti Super 16GB or equivalent
- **RAM**: 32GB DDR4/DDR5
- **Storage**: 50GB free space
- **OS**: Windows 10/11 (64-bit)

### **Optimal Setup (Recommended)**
- **Primary GPU**: RTX 4090 24GB (for LLM text generation)
- **Secondary GPU**: RTX 4070Ti Super 16GB (for embeddings & search)
- **RAM**: 32GB+ DDR5
- **Storage**: NVMe SSD for model caching

### **Future Upgrade Path**
- Support for 4x GPU configurations (RTX 5060Ti/5070Ti/5080 16GB)
- Scalable architecture for enterprise deployment

## âš¡ **Quick Start**

### **1. Clone Repository**
```bash
git clone https://github.com/yourusername/ai-sales-chatbot.git
cd ai-sales-chatbot
```

### **2. Automated Setup (Windows)**
```bash
# Run setup script as Administrator
setup.bat
```

### **3. Manual Installation**
```bash
# Install Python 3.9+ with CUDA support
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# Install dependencies
pip install -r requirements.txt
```

### **4. Launch Application**
```bash
python sales_chatbot.py
```

## ğŸ“Š **System Architecture**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   User Input    â”‚â”€â”€â”€â–¶â”‚   Intent         â”‚â”€â”€â”€â–¶â”‚   Response      â”‚
â”‚                 â”‚    â”‚   Classification â”‚    â”‚   Generation    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚                        â–²
                                â–¼                        â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Local DB      â”‚â—„â”€â”€â”€â”‚   Semantic       â”‚â”€â”€â”€â–¶â”‚   LLM Model     â”‚
â”‚   Search        â”‚    â”‚   Search Engine  â”‚    â”‚   (Llama 2)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                        â–²
         â–¼                       â–¼                        â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚   Google        â”‚    â”‚   Product        â”‚              â”‚
â”‚   Search        â”‚    â”‚   Database       â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”§ **GPU Optimization**

### **Heterogeneous GPU Allocation**
```yaml
RTX 4090 24GB (Primary):
  â”œâ”€â”€ LLM Text Generation (Llama 2 7B/13B)
  â”œâ”€â”€ Conversation Context Management  
  â””â”€â”€ Response Generation Pipeline

RTX 4070Ti Super 16GB (Secondary):
  â”œâ”€â”€ Sentence Embeddings
  â”œâ”€â”€ Product Database Search
  â”œâ”€â”€ Intent Classification
  â””â”€â”€ OCR Image Processing
```

### **Performance Benchmarks**
| Configuration | Response Time | Concurrent Users | VRAM Usage |
|---------------|---------------|------------------|------------|
| Single RTX 4090 | 3.2s | 3-5 users | 18GB |
| RTX 4090 + RTX 4070Ti Super | 2.1s | 8-12 users | 24GB |
| 4x RTX 5080 (Future) | 1.2s | 20+ users | 64GB |

## ğŸ“š **Documentation**

- ğŸ“– **[Installation Guide](INSTALLATION.md)** - Detailed setup instructions
- ğŸš€ **[Quick Start Guide](QUICK_START.md)** - Get running in 15 minutes  
- âš™ï¸ **[GPU Optimization](gpu_optimization.py)** - Multi-GPU configuration
- ğŸ“Š **[Performance Tuning](docs/performance.md)** - Optimization tips

## ğŸ—‚ï¸ **Project Structure**

```
ai-sales-chatbot/
â”œâ”€â”€ ğŸ“„ sales_chatbot.py          # Main application
â”œâ”€â”€ ğŸ“„ requirements.txt          # Dependencies
â”œâ”€â”€ ğŸ“„ setup.bat                 # Windows setup script
â”œâ”€â”€ ğŸ“„ gpu_optimization.py       # GPU management
â”œâ”€â”€ ğŸ“ config/                   # Configuration files
â”‚   â””â”€â”€ chatbot_config.yaml
â”œâ”€â”€ ğŸ“ data/                     # Training data
â”‚   â”œâ”€â”€ excel/                   # Product catalogs
â”‚   â”œâ”€â”€ pdf/                     # Documentation
â”‚   â”œâ”€â”€ word/                    # Product manuals
â”‚   â””â”€â”€ images/                  # Product images
â”œâ”€â”€ ğŸ“ logs/                     # Application logs
â””â”€â”€ ğŸ“ models/                   # AI model cache
```

## ğŸ“ **Usage Examples**

### **Training with Product Data**
```python
# Upload Excel product catalog
# Expected columns: name, description, category, price, features
chatbot.process_excel_file("products.xlsx")

# Process PDF documentation  
chatbot.process_pdf_file("product_manual.pdf")

# OCR from product images
chatbot.process_image_file("product_photo.jpg")
```

### **Natural Language Queries**
```python
# Product search
"Show me gaming laptops under $2000 with RTX graphics"

# Feature comparison  
"What's the difference between your business and gaming laptops?"

# Technical specifications
"I need a computer for video editing with 32GB RAM"

# Availability check
"Do you have any wireless mice in stock?"
```

### **Conversation Context**
```python
User: "I need a laptop for gaming"
AI: "I'd recommend our Gaming Laptop Pro X1..."

User: "What about the warranty?"  # Context aware
AI: "The Gaming Laptop Pro X1 comes with a 2-year warranty..."

User: "Any discounts available?"  # Still context aware  
AI: "For the Gaming Laptop Pro X1, we currently have..."
```

## ğŸ”§ **Configuration**

### **AI Model Selection**
```yaml
# config/chatbot_config.yaml
ai_models:
  primary_llm: "meta-llama/Llama-2-7b-chat-hf"
  fallback_llm: "microsoft/DialoGPT-medium" 
  embedding_model: "sentence-transformers/all-MiniLM-L6-v2"

gpu_config:
  use_quantization: true    # 8-bit for memory savings
  mixed_precision: true     # Speed optimization
  max_memory_per_gpu: 0.8   # Use 80% of VRAM
```

### **Search Configuration**
```yaml
search_config:
  local_similarity_threshold: 0.7  # Minimum similarity for local results
  enable_google_search: true       # Fallback to web search
  max_google_results: 3            # Number of web results to consider

response_config:
  max_response_length: 512     # Maximum response tokens
  temperature: 0.7             # Response creativity
  repetition_penalty: 1.1      # Avoid repetition
```

## ğŸ“ˆ **Performance Monitoring**

The system includes comprehensive analytics:

- ğŸ“Š **Response Time Tracking** - Monitor AI performance
- ğŸ” **Search Success Rates** - Local vs web search usage  
- ğŸ’¾ **Memory Usage** - GPU and system memory monitoring
- ğŸŒ¡ï¸ **Temperature Monitoring** - GPU temperature tracking
- âš¡ **Power Consumption** - GPU power usage analytics

## ğŸ› ï¸ **Development**

### **Adding Custom Models**
```python
# Extend model support in sales_chatbot.py
def load_custom_model(self, model_name):
    self.custom_model = AutoModelForCausalLM.from_pretrained(
        model_name,
        device_map={"": self.primary_device}
    )
```

### **Custom Response Flows**
```yaml
# Add to config/chatbot_config.yaml
response_flows:
  pricing_inquiry: "Let me help you with pricing information..."
  technical_support: "I can provide technical assistance..."
  product_comparison: "I'll compare these products for you..."
```

### **Database Schema**
```sql
-- Products table
CREATE TABLE products (
    id INTEGER PRIMARY KEY,
    name TEXT NOT NULL,
    description TEXT,
    category TEXT,
    price REAL,
    features TEXT,
    specifications TEXT,
    availability TEXT
);

-- Conversations table  
CREATE TABLE conversations (
    id INTEGER PRIMARY KEY,
    timestamp TEXT,
    user_input TEXT,
    bot_response TEXT,
    data_source TEXT,
    response_time REAL
);
```

## ğŸš€ **Deployment Options**

### **Desktop Application**
- Windows GUI with Tkinter
- Local database and models
- No internet dependency for core features

### **Web Service** 
```python
# Optional FastAPI deployment
pip install fastapi uvicorn
python -m uvicorn api_server:app --host 0.0.0.0 --port 8000
```

### **Docker Deployment**
```dockerfile
FROM nvidia/cuda:11.8-devel-ubuntu20.04
COPY . /app
WORKDIR /app
RUN pip install -r requirements.txt
CMD ["python", "sales_chatbot.py"]
```

## ğŸ¤ **Contributing**

1. **Fork the repository**
2. **Create feature branch** (`git checkout -b feature/amazing-feature`)
3. **Commit changes** (`git commit -m 'Add amazing feature'`)
4. **Push to branch** (`git push origin feature/amazing-feature`)
5. **Open Pull Request**

### **Development Setup**
```bash
# Install development dependencies
pip install pytest black flake8

# Run tests
pytest tests/

# Format code
black sales_chatbot.py

# Lint code  
flake8 sales_chatbot.py
```

## ğŸ“ **License**

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ **Acknowledgments**

- **Hugging Face** - For transformer models and tools
- **Meta AI** - For Llama 2 language models  
- **Sentence Transformers** - For semantic search capabilities
- **PyTorch** - For deep learning framework
- **NVIDIA** - For CUDA and GPU acceleration

## ğŸ“ **Support**

- ğŸ“§ **Email**: your-email@example.com
- ğŸ’¬ **Discord**: [Your Discord Server](https://discord.gg/yourserver)
- ğŸ› **Issues**: [GitHub Issues](https://github.com/yourusername/ai-sales-chatbot/issues)
- ğŸ“– **Documentation**: [Wiki](https://github.com/yourusername/ai-sales-chatbot/wiki)

## ğŸ—ºï¸ **Roadmap**

### **Version 2.0** (Q2 2024)
- [ ] Web-based interface with Gradio/Streamlit
- [ ] Multi-language support
- [ ] Voice chat capabilities
- [ ] CRM system integration (Salesforce, HubSpot)

### **Version 3.0** (Q3 2024)  
- [ ] Cloud deployment support (AWS, Azure, GCP)
- [ ] Advanced analytics dashboard
- [ ] A/B testing for response optimization
- [ ] Enterprise user management

### **Version 4.0** (Q4 2024)
- [ ] 4x GPU cluster support
- [ ] Advanced model fine-tuning
- [ ] Real-time learning from conversations
- [ ] API marketplace integration

---

â­ **Star this repository** if you find it helpful!

ğŸ“¢ **Share with others** who might benefit from AI-powered sales assistance!

ğŸ”” **Watch for updates** to stay informed about new features!
